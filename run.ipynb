{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install monai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i81pbUCGIMbp",
        "outputId": "6f3d0066-42e7-45ff-e0dd-69faae457f23"
      },
      "id": "i81pbUCGIMbp",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from monai) (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n",
            "Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, monai\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed monai-1.4.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_id",
        "outputId": "0597ad7a-74d0-404d-a5ae-8a7d5a74db29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n",
            "AttentionUnet(\n",
            "  (model): Sequential(\n",
            "    (0): ConvBlock(\n",
            "      (conv): Sequential(\n",
            "        (0): Convolution(\n",
            "          (conv): Conv3d(1, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adn): ADN(\n",
            "            (N): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (D): Dropout(p=0.0, inplace=False)\n",
            "            (A): ReLU()\n",
            "          )\n",
            "        )\n",
            "        (1): Convolution(\n",
            "          (conv): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "          (adn): ADN(\n",
            "            (N): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (D): Dropout(p=0.0, inplace=False)\n",
            "            (A): ReLU()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): AttentionLayer(\n",
            "      (attention): AttentionBlock(\n",
            "        (W_g): Sequential(\n",
            "          (0): Convolution(\n",
            "            (conv): Conv3d(16, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "          )\n",
            "          (1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (W_x): Sequential(\n",
            "          (0): Convolution(\n",
            "            (conv): Conv3d(16, 8, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "          )\n",
            "          (1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (psi): Sequential(\n",
            "          (0): Convolution(\n",
            "            (conv): Conv3d(8, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "          )\n",
            "          (1): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): Sigmoid()\n",
            "        )\n",
            "        (relu): ReLU()\n",
            "      )\n",
            "      (upconv): UpConv(\n",
            "        (up): Convolution(\n",
            "          (conv): ConvTranspose3d(32, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
            "          (adn): ADN(\n",
            "            (N): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (D): Dropout(p=0.0, inplace=False)\n",
            "            (A): ReLU()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (merge): Convolution(\n",
            "        (conv): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "        (adn): ADN(\n",
            "          (N): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          (D): Dropout(p=0.0, inplace=False)\n",
            "          (A): PReLU(num_parameters=1)\n",
            "        )\n",
            "      )\n",
            "      (submodule): Sequential(\n",
            "        (0): ConvBlock(\n",
            "          (conv): Sequential(\n",
            "            (0): Convolution(\n",
            "              (conv): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "              (adn): ADN(\n",
            "                (N): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (D): Dropout(p=0.0, inplace=False)\n",
            "                (A): ReLU()\n",
            "              )\n",
            "            )\n",
            "            (1): Convolution(\n",
            "              (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "              (adn): ADN(\n",
            "                (N): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (D): Dropout(p=0.0, inplace=False)\n",
            "                (A): ReLU()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): AttentionLayer(\n",
            "          (attention): AttentionBlock(\n",
            "            (W_g): Sequential(\n",
            "              (0): Convolution(\n",
            "                (conv): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "              )\n",
            "              (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (W_x): Sequential(\n",
            "              (0): Convolution(\n",
            "                (conv): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "              )\n",
            "              (1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "            (psi): Sequential(\n",
            "              (0): Convolution(\n",
            "                (conv): Conv3d(16, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "              )\n",
            "              (1): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (2): Sigmoid()\n",
            "            )\n",
            "            (relu): ReLU()\n",
            "          )\n",
            "          (upconv): UpConv(\n",
            "            (up): Convolution(\n",
            "              (conv): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
            "              (adn): ADN(\n",
            "                (N): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                (D): Dropout(p=0.0, inplace=False)\n",
            "                (A): ReLU()\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (merge): Convolution(\n",
            "            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "            (adn): ADN(\n",
            "              (N): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "              (D): Dropout(p=0.0, inplace=False)\n",
            "              (A): PReLU(num_parameters=1)\n",
            "            )\n",
            "          )\n",
            "          (submodule): Sequential(\n",
            "            (0): ConvBlock(\n",
            "              (conv): Sequential(\n",
            "                (0): Convolution(\n",
            "                  (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "                  (adn): ADN(\n",
            "                    (N): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                    (D): Dropout(p=0.0, inplace=False)\n",
            "                    (A): ReLU()\n",
            "                  )\n",
            "                )\n",
            "                (1): Convolution(\n",
            "                  (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "                  (adn): ADN(\n",
            "                    (N): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                    (D): Dropout(p=0.0, inplace=False)\n",
            "                    (A): ReLU()\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "            (1): AttentionLayer(\n",
            "              (attention): AttentionBlock(\n",
            "                (W_g): Sequential(\n",
            "                  (0): Convolution(\n",
            "                    (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "                  )\n",
            "                  (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                )\n",
            "                (W_x): Sequential(\n",
            "                  (0): Convolution(\n",
            "                    (conv): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "                  )\n",
            "                  (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                )\n",
            "                (psi): Sequential(\n",
            "                  (0): Convolution(\n",
            "                    (conv): Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "                  )\n",
            "                  (1): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (2): Sigmoid()\n",
            "                )\n",
            "                (relu): ReLU()\n",
            "              )\n",
            "              (upconv): UpConv(\n",
            "                (up): Convolution(\n",
            "                  (conv): ConvTranspose3d(128, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
            "                  (adn): ADN(\n",
            "                    (N): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                    (D): Dropout(p=0.0, inplace=False)\n",
            "                    (A): ReLU()\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "              (merge): Convolution(\n",
            "                (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "                (adn): ADN(\n",
            "                  (N): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                  (D): Dropout(p=0.0, inplace=False)\n",
            "                  (A): PReLU(num_parameters=1)\n",
            "                )\n",
            "              )\n",
            "              (submodule): Sequential(\n",
            "                (0): ConvBlock(\n",
            "                  (conv): Sequential(\n",
            "                    (0): Convolution(\n",
            "                      (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "                      (adn): ADN(\n",
            "                        (N): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                        (D): Dropout(p=0.0, inplace=False)\n",
            "                        (A): ReLU()\n",
            "                      )\n",
            "                    )\n",
            "                    (1): Convolution(\n",
            "                      (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "                      (adn): ADN(\n",
            "                        (N): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                        (D): Dropout(p=0.0, inplace=False)\n",
            "                        (A): ReLU()\n",
            "                      )\n",
            "                    )\n",
            "                  )\n",
            "                )\n",
            "                (1): AttentionLayer(\n",
            "                  (attention): AttentionBlock(\n",
            "                    (W_g): Sequential(\n",
            "                      (0): Convolution(\n",
            "                        (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "                      )\n",
            "                      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                    )\n",
            "                    (W_x): Sequential(\n",
            "                      (0): Convolution(\n",
            "                        (conv): Conv3d(128, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "                      )\n",
            "                      (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                    )\n",
            "                    (psi): Sequential(\n",
            "                      (0): Convolution(\n",
            "                        (conv): Conv3d(64, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "                      )\n",
            "                      (1): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                      (2): Sigmoid()\n",
            "                    )\n",
            "                    (relu): ReLU()\n",
            "                  )\n",
            "                  (upconv): UpConv(\n",
            "                    (up): Convolution(\n",
            "                      (conv): ConvTranspose3d(256, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
            "                      (adn): ADN(\n",
            "                        (N): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                        (D): Dropout(p=0.0, inplace=False)\n",
            "                        (A): ReLU()\n",
            "                      )\n",
            "                    )\n",
            "                  )\n",
            "                  (merge): Convolution(\n",
            "                    (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "                    (adn): ADN(\n",
            "                      (N): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                      (D): Dropout(p=0.0, inplace=False)\n",
            "                      (A): PReLU(num_parameters=1)\n",
            "                    )\n",
            "                  )\n",
            "                  (submodule): ConvBlock(\n",
            "                    (conv): Sequential(\n",
            "                      (0): Convolution(\n",
            "                        (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "                        (adn): ADN(\n",
            "                          (N): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                          (D): Dropout(p=0.0, inplace=False)\n",
            "                          (A): ReLU()\n",
            "                        )\n",
            "                      )\n",
            "                      (1): Convolution(\n",
            "                        (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "                        (adn): ADN(\n",
            "                          (N): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                          (D): Dropout(p=0.0, inplace=False)\n",
            "                          (A): ReLU()\n",
            "                        )\n",
            "                      )\n",
            "                    )\n",
            "                  )\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): Convolution(\n",
            "      (conv): Conv3d(16, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-bb979720d23a>:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(MODEL_CHECKPOINT, map_location=DEVICE)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3 NIfTI cases. Running inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/data_samples/predsTr/ATM_001_0000.nii.gz\n",
            "Saved: /content/data_samples/predsTr/ATM_002_0000.nii.gz\n",
            "Saved: /content/data_samples/predsTr/ATM_004_0000.nii.gz\n",
            "Inference completed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.transforms import (\n",
        "    LoadImaged, EnsureChannelFirstd, CropForegroundd, ScaleIntensityRanged, Rotate90, Rotate90d, ToTensord,\n",
        "    AsDiscrete, Compose\n",
        ")\n",
        "from monai.data import Dataset, DataLoader, decollate_batch\n",
        "from utils import get_model  # Ensure this function is available for loading your model\n",
        "\n",
        "# Set up inference parameters\n",
        "MODEL_CHECKPOINT = \"/content/models/bel_old/best_metric_awc_64-0.87.ckpt\"  # Update with your model path\n",
        "INPUT_IMAGE_DIR = \"/content/data_samples/imagesTr/\"  # Directory containing NIfTI images\n",
        "INPUT_LUNG_DIR = \"/content/data_samples/lungsTr/\"  # Directory containing NIfTI lung masks\n",
        "OUTPUT_DIR = \"/content/data_samples/predsTr/\"  # Where to save results\n",
        "PATCH_SIZE = (256, 256, 256)  # Update as needed\n",
        "BATCH_SIZE = 1  # Adjust based on available memory\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "params_dict = {\n",
        "    'PATCH_SIZE': (PATCH_SIZE, PATCH_SIZE, PATCH_SIZE),\n",
        "    'BATCH_SIZE': 1,\n",
        "    'MAX_CARDINALITY': 120,\n",
        "    'NUM_WORKERS': 0,\n",
        "    'PIN_MEMORY': True,\n",
        "    'AVAILABLE_GPUs': torch.cuda.device_count(),\n",
        "}\n",
        "params={\"MODEL_NAME\": \"AttentionUNet\",\n",
        "        \"IN_CHANNELS\": 1,\n",
        "        \"OUT_CHANNELS\": 1,\n",
        "        \"CHANNELS\": 16,\n",
        "        \"N_LAYERS\": 5,\n",
        "        \"STRIDES\": 2,\n",
        "        \"SPATIAL_DIMS\": 3,\n",
        "        \"DROPOUT\": 0.0\n",
        "        }\n",
        "# Load the trained model\n",
        "print(\"Loading model...\")\n",
        "model = get_model(params)  # Adjust params\n",
        "print(model)\n",
        "# Load the checkpoint\n",
        "checkpoint = torch.load(MODEL_CHECKPOINT, map_location=DEVICE)\n",
        "\n",
        "# Modify the state_dict to remove \"_model.\" prefix from keys\n",
        "new_state_dict = {}\n",
        "for key, value in checkpoint[\"state_dict\"].items():\n",
        "    new_key = key.replace(\"_model.\", \"\")  # Remove the prefix\n",
        "    new_state_dict[new_key] = value\n",
        "\n",
        "# Load the modified state_dict into the model\n",
        "model.load_state_dict(new_state_dict, strict=False)\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "\n",
        "# Define preprocessing pipeline using Compose\n",
        "preprocess = Compose([\n",
        "    LoadImaged(keys=[\"image\", \"lung\"], image_only=False),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"lung\"]),\n",
        "    CropForegroundd(keys=[\"image\", \"lung\"], source_key=\"lung\", margin=[1, 1, 50], allow_smaller=True),\n",
        "    ScaleIntensityRanged(\n",
        "        keys=\"image\",\n",
        "        a_min=-1000,  # Adjust based on your dataset\n",
        "        a_max=600,\n",
        "        b_min=0.0,\n",
        "        b_max=1.0,\n",
        "        clip=True\n",
        "    ),\n",
        "    Rotate90d(keys=[\"image\", \"lung\"], k=3),\n",
        "    ToTensord(keys=[\"image\", \"lung\"], dtype=torch.float32),\n",
        "])\n",
        "\n",
        "# Define post-processing pipeline\n",
        "post_pred = Compose([\n",
        "            AsDiscrete(threshold=0.5),\n",
        "            Rotate90(k=1, spatial_axes=(0, 1))\n",
        "        ])\n",
        "# Ensure output directory exists\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# List all NIfTI files\n",
        "image_files = [f for f in os.listdir(INPUT_IMAGE_DIR) if f.endswith(\".nii\") or f.endswith(\".nii.gz\")]\n",
        "\n",
        "# Create dataset for preprocessing\n",
        "data_list = []\n",
        "for file in image_files:\n",
        "    image_path = os.path.join(INPUT_IMAGE_DIR, file)\n",
        "    lung_path = os.path.join(INPUT_LUNG_DIR, file)  # Assumes lung mask has the same filename\n",
        "    if os.path.exists(lung_path):\n",
        "        data_list.append({\"image\": image_path, \"lung\": lung_path})\n",
        "    else:\n",
        "        print(f\"Skipping {file}: Corresponding lung mask not found.\")\n",
        "\n",
        "# Create DataLoader\n",
        "dataset = Dataset(data=data_list, transform=preprocess)\n",
        "dataloader = DataLoader(dataset, batch_size=1, num_workers=4)\n",
        "\n",
        "print(f\"Found {len(dataset)} NIfTI cases. Running inference...\")\n",
        "\n",
        "# Perform inference on each file\n",
        "with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "        file_name = os.path.basename(batch[\"image_meta_dict\"][\"filename_or_obj\"][0])  # Extract filename\n",
        "\n",
        "        # Move tensors to device\n",
        "        input_tensor = batch[\"image\"].to(DEVICE)\n",
        "\n",
        "        # Run model inference\n",
        "        output_tensor = sliding_window_inference(\n",
        "            inputs=input_tensor, roi_size=PATCH_SIZE, sw_batch_size=BATCH_SIZE, predictor=model, overlap=0.25\n",
        "        )\n",
        "        tst_outputs = [post_pred(i) for i in decollate_batch(output_tensor)]\n",
        "        tst_filename = batch['image_meta_dict']['filename_or_obj'][0].split('/')[-1].split('.')[0]\n",
        "        affine = batch['image_meta_dict']['affine'][0]\n",
        "        spt_size = batch['image_meta_dict']['spatial_shape'][0].tolist()\n",
        "        x1, x2, x3 = batch['foreground_start_coord'][0][0], batch['foreground_start_coord'][0][1], \\\n",
        "            batch['foreground_start_coord'][0][2]\n",
        "        y1, y2, y3 = batch['foreground_end_coord'][0][0], batch['foreground_end_coord'][0][1], \\\n",
        "            batch['foreground_end_coord'][0][2]\n",
        "\n",
        "        output_corr = np.zeros(spt_size)\n",
        "        label_corr = np.zeros(spt_size)\n",
        "\n",
        "        output_corr[x1:y1, x2:y2, x3:y3] = np.squeeze(tst_outputs[0].type(torch.int64).cpu().numpy())\n",
        "\n",
        "\n",
        "        # Load original NIfTI to keep affine and header\n",
        "        original_nifti = nib.load(batch[\"image_meta_dict\"][\"filename_or_obj\"][0])\n",
        "\n",
        "        # Save the predicted segmentation\n",
        "        output_nifti = nib.Nifti1Image(output_corr, affine=affine, header=original_nifti.header)\n",
        "        output_path = os.path.join(OUTPUT_DIR, file_name)\n",
        "        nib.save(output_nifti, output_path)\n",
        "\n",
        "        print(f\"Saved: {output_path}\")\n",
        "\n",
        "print(\"Inference completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Load NIfTI file\n",
        "nii_path = \"/content/data_samples/predsTr/ATM_001_0000.nii.gz\"\n",
        "nifti_img = nib.load(nii_path)\n",
        "nifti_data = nifti_img.get_fdata()\n",
        "\n",
        "# Get shape of the volume\n",
        "depth = nifti_data.shape[2]  # Assuming the 3rd axis is the depth\n",
        "\n",
        "# Select random slices\n",
        "num_slices = 5  # Number of slices to visualize\n",
        "random_slices = sorted(random.sample(range(depth), num_slices))\n",
        "\n",
        "# Plot the selected slices\n",
        "fig, axes = plt.subplots(1, num_slices, figsize=(15, 5))\n",
        "for i, slice_idx in enumerate(random_slices):\n",
        "    axes[i].imshow(nifti_data[:, :, slice_idx], cmap=\"gray\")\n",
        "    axes[i].set_title(f\"Slice {slice_idx}\")\n",
        "    axes[i].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NNSHxCLlL-W7",
        "outputId": "eaef730f-a2ec-40cc-fbc4-ada8a2196f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "id": "NNSHxCLlL-W7",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IzYiZRH2Tr0I"
      },
      "id": "IzYiZRH2Tr0I",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}